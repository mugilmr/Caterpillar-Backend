# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BU5QJ7ZdecCxB8YvVJy7DqqgLf4VQXzQ
"""

import pandas as pd
import matplotlib.pyplot as plt
import re
import numpy as np
from datetime import datetime
import math

def predict_failure(file):
    data = pd.read_excel(file)
    threshold = pd.read_excel(file, sheet_name=1)

    """There are total 50 Id
    Each Id is having 20 rows
    so total 50*20 = 1000 rows
    """

    plt.bar(data['Id'].value_counts().index, data['Id'].value_counts())
    plt.title('ID count')
    plt.xlabel('ID')

    data['Id'].nunique()

    """#There are total 5 Machines
    Each machine is having 200 values
    So total 200*5= 1000 rows
    """

    plt.bar(data['Machine'].value_counts().index, data['Machine'].value_counts())
    plt.title('Machine count')
    plt.xlabel('Machine')
    plt.xticks(rotation=45)

    machine_list = data['Machine'].unique()

    """Each Id is having 4 values for each machine
    So total 5machine * 4 values = 20 rows for each ID
    """

    data[data['Machine'] == 'Excavator_1'].groupby(by=['Machine', 'Id']).count()

    data[data['Machine'] == 'Articulated_Truck_1'].groupby(by=['Machine', 'Id']).count()

    """Each Machine is having 4 components
    50 values each
    so 50*4=200 values for each machine
    """

    data.groupby(by=['Machine', 'Component']).count()['Id']

    """Each Id has 5 values for every component
    so total 4 component*5 = 20 values for each Id
    """

    data.groupby(by=['Id', 'Component']).count()['Value']

    """Breakdown of Component and parameter count"""

    data[data['Machine'] == machine_list[0]].groupby(by=['Component', 'Parameter']).count()['Id']

    data[data['Machine'] == machine_list[1]].groupby(by=['Component', 'Parameter']).count()['Id']

    data[data['Machine'] == machine_list[2]].groupby(by=['Component', 'Parameter']).count()['Id']

    data[data['Machine'] == machine_list[3]].groupby(by=['Component', 'Parameter']).count()['Id']

    data[data['Machine'] == machine_list[4]].groupby(by=['Component', 'Parameter']).count()['Id']

    parameter = threshold['Parameter']

    combined_param_list = []
    for idx in range(data.shape[0]):
        row = data.iloc[idx, :]
        combined = row['Component'] + ' ' + row['Parameter']
        if not combined in combined_param_list:
            combined_param_list.append(combined)
        # break

    new_param_mapping = {}

    new_param_mapping['Engine Temparature'] = 'Engine Temparature'
    new_param_mapping['Fuel Water in Fuel'] = 'Water Fuel'
    new_param_mapping['Drive Transmission Pressure'] = 'Transmission Pressure'
    new_param_mapping['Engine Oil Pressure'] = 'Engine Oil Pressure'
    new_param_mapping['Fuel Temparature'] = 'Fuel Temparature'
    new_param_mapping['Drive Brake Control'] = 'Brake Control'
    new_param_mapping['Drive Pedal Sensor'] = 'Pedal Sensor'
    new_param_mapping['Misc Exhaust Gas Temparature'] = 'Exhaust Gas Temparature'
    new_param_mapping['Misc Air Filter Pressure'] = 'Air Filter Pressure Drop'
    new_param_mapping['Misc System Voltage'] = 'System Voltage'
    new_param_mapping['Misc Hydraulic Pump Rate'] = 'Hydraulic Pump Rate'
    new_param_mapping['Engine Speed'] = 'Engine Speed'
    new_param_mapping['Fuel Level'] = 'Fuel Level'
    new_param_mapping['Fuel Pressure'] = 'Fuel Pressure'

    new_param_mapping

    data['param_new'] = data['Component'] + ' ' + data['Parameter']

    data['param_mapping'] = data['param_new']
    data['param_mapping'] = data['param_mapping'].map(new_param_mapping)

    data['param_mapping']

    low_threshold = []
    high_threshold = []
    for t in threshold['Treshold']:
        if 'Low' in t:
            print(t)
            # regex = (r'Low\s+(.*)')
            regex = (r'[\s0-9]+')
            match1 = re.findall(regex, t)
            low = int(match1[0])
            low_threshold.append(low)
        else:
            low_threshold.append(np.nan)
        if 'High' in t:
            print(t)
            regex = (r'High\s+(.*)')
            match1 = re.findall(regex, t)
            high = float(match1[0])
            high_threshold.append(high)
        else:
            high_threshold.append(np.nan)

    threshold['low thres'] = low_threshold
    threshold['high thres'] = high_threshold

    data[data['Parameter'] == 'Air Filter Pressure']['Value'].max()



    # string_date = list(data['Time'][800:])
    string_date=list(data.loc[800:,'Time'])

    # date_str = '2022-05-02T02:13:44'.replace('T',' ')
    converted_date = []
    date_format = '%Y-%m-%d %H:%M:%SZ'
    for dt in string_date:
        date_str = dt.replace('T', ' ')
        # print(date_str)
        date_obj = datetime.strptime(date_str, date_format)
        converted_date.append(date_obj)
        # print(date_obj)
    # data['Time'][800:] = converted_date
    data.loc[800:, 'Time']=converted_date

    data.sort_values(by='Time')

    data.groupby(by='param_mapping').min()['Value']

    data.groupby(by='param_mapping').min()['Value']['Fuel Level']

    data.groupby(by='param_mapping').max()['Value']

    max_dict = data.groupby(by='param_mapping').max()['Value'].to_dict()
    min_dict = data.groupby(by='param_mapping').min()['Value'].to_dict()

    exist_min = dict(zip(threshold['Parameter'], threshold['low thres']))
    exist_max = dict(zip(threshold['Parameter'], threshold['high thres']))

    low_threshold = threshold['low thres'].isna()
    new_low_threshold = {}
    for l in range(threshold.shape[0]):
        p_name = threshold.iloc[l]['Parameter']
        # print(p_name,threshold.iloc[l]['low thres']==np.nan)
        if low_threshold[l] == True:
            new_low_threshold[p_name] = min_dict[p_name]
        else:
            new_low_threshold[p_name] = exist_min[p_name]



    high_threshold = threshold['high thres'].isna()
    new_high_threshold = {}
    for l in range(threshold.shape[0]):
        p_name = threshold.iloc[l]['Parameter']
        # print(p_name,threshold.iloc[l]['low thres']==np.nan)
        if high_threshold[l] == True:
            new_high_threshold[p_name] = max_dict[p_name]
        else:
            new_high_threshold[p_name] = exist_max[p_name]



    threshold['low thres_'] = threshold['Parameter'].map(new_low_threshold)
    threshold['high thres_'] = threshold['Parameter'].map(new_high_threshold)

    threshold['medium'] = threshold[['low thres_', 'high thres_']].mean(axis=1)

    threshold['param_mapping'] = threshold['Parameter']

    new_data = pd.merge(data[['Time', 'param_mapping', 'Value']],
                        threshold[['param_mapping', 'Probability of Failure', 'low thres_', 'high thres_', 'medium']],
                        on='param_mapping')

    new_data = pd.merge(data[['Time', 'param_mapping', 'Value']],
                        threshold[['param_mapping', 'Probability of Failure', 'low thres', 'high thres']],
                        on='param_mapping')

    target = []
    for idx in range(new_data.shape[0]):
        row = new_data.iloc[idx]
        param = row['param_mapping']
        if math.isnan(exist_min[param]):
            high = row['high thres']
            if row['Value'] > (high - (high * 0.1)):
                target.append('Will Fail')
            else:
                target.append('Safe')
        elif math.isnan(exist_max[param]):
            low = row['low thres']
            if row['Value'] < (low + (low * 0.1)):
                target.append('Will Fail')
            else:
                target.append('Safe')
        else:
            mean_std_minus = row[['low thres', 'high thres']].mean() - row[['low thres', 'high thres']].std()
            mean_std_plus = row[['low thres', 'high thres']].mean() + row[['low thres', 'high thres']].std()

            if row['Value'] < mean_std_minus or row['Value'] > mean_std_plus:
                target.append('Will Fail')
            else:
                target.append('Safe')

    new_data['target'] = target

    merged_df = pd.merge(new_data, data, on='Time', how='left')

    columns = ['Id', 'Component', 'Parameter', 'Value_y', 'param_new', 'param_mapping_y']

    merged_df = merged_df.drop(columns=columns)
    return merged_df
